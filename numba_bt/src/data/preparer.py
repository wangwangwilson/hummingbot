"""æ•°æ®å‡†å¤‡æ¨¡å—ï¼šä»æ•°æ®æºè¯»å–å¹¶å‡†å¤‡å›æµ‹æ•°æ®"""
import sys
from pathlib import Path
from datetime import datetime
from typing import Optional, List, Tuple
import numpy as np
import duckdb

# æ·»åŠ  bigdata_plan åˆ°è·¯å¾„ä»¥å¤ç”¨æ•°æ®è¯»å–å™¨
bigdata_plan_path = Path(__file__).parent.parent.parent.parent / "bigdata_plan"
if str(bigdata_plan_path) not in sys.path:
    sys.path.insert(0, str(bigdata_plan_path))

# ä¹Ÿå°è¯•ç›´æ¥æ·»åŠ ç»å¯¹è·¯å¾„
bigdata_plan_abs = Path("/home/wilson/bigdata_plan")
if str(bigdata_plan_abs) not in sys.path and bigdata_plan_abs.exists():
    sys.path.insert(0, str(bigdata_plan_abs))

try:
    from src.utils.data_reader import BinanceDataReader
    from src.const import BINANCE_AGGTrades_DIR
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
    BINANCE_AGGTrades_DIR = "/mnt/hdd/data"
    BinanceDataReader = None

# å•ç‹¬å°è¯•å¯¼å…¥FundingRateReaderï¼Œå› ä¸ºå®ƒçš„ä¾èµ–å¯èƒ½ä¸åŒ
FundingRateReader = None
try:
    # å…ˆç¡®ä¿bigdata_planåœ¨sys.pathä¸­
    if str(bigdata_plan_abs) not in sys.path:
        sys.path.insert(0, str(bigdata_plan_abs))
    
    from src.utils.funding_rate_reader import FundingRateReader
    print(f"  âœ… FundingRateReader å¯¼å…¥æˆåŠŸï¼ˆæ ‡å‡†å¯¼å…¥ï¼‰")
except ImportError as e:
    try:
        # å°è¯•ä»ç»å¯¹è·¯å¾„å¯¼å…¥
        import importlib.util
        funding_reader_path = bigdata_plan_abs / "src" / "utils" / "funding_rate_reader.py"
        if funding_reader_path.exists():
            # ä¸´æ—¶æ·»åŠ bigdata_planåˆ°sys.path
            if str(bigdata_plan_abs) not in sys.path:
                sys.path.insert(0, str(bigdata_plan_abs))
            
            # å…ˆå¯¼å…¥ä¾èµ–æ¨¡å—
            try:
                # å¯¼å…¥const
                const_path = bigdata_plan_abs / "src" / "const.py"
                if const_path.exists():
                    const_spec = importlib.util.spec_from_file_location("src.const", const_path)
                    const_module = importlib.util.module_from_spec(const_spec)
                    const_spec.loader.exec_module(const_module)
                    # å°†constæ¨¡å—æ·»åŠ åˆ°sys.modulesï¼Œä»¥ä¾¿funding_rate_readerå¯ä»¥å¯¼å…¥
                    if 'src' not in sys.modules:
                        import types
                        sys.modules['src'] = types.ModuleType('src')
                    if 'src.utils' not in sys.modules:
                        import types
                        sys.modules['src.utils'] = types.ModuleType('src.utils')
                    sys.modules['src.const'] = const_module
                
                # å¯¼å…¥zip_validator
                zip_validator_path = bigdata_plan_abs / "src" / "utils" / "zip_validator.py"
                if zip_validator_path.exists():
                    zip_validator_spec = importlib.util.spec_from_file_location("src.utils.zip_validator", zip_validator_path)
                    zip_validator_module = importlib.util.module_from_spec(zip_validator_spec)
                    zip_validator_spec.loader.exec_module(zip_validator_module)
                    sys.modules['src.utils.zip_validator'] = zip_validator_module
            except Exception as dep_e:
                print(f"  âš ï¸  ä¾èµ–æ¨¡å—å¯¼å…¥å¤±è´¥: {dep_e}")
            
            spec = importlib.util.spec_from_file_location("funding_rate_reader", funding_reader_path)
            funding_reader_module = importlib.util.module_from_spec(spec)
            # è®¾ç½®æ¨¡å—çš„__file__å±æ€§ï¼Œä»¥ä¾¿ç›¸å¯¹å¯¼å…¥èƒ½å·¥ä½œ
            funding_reader_module.__file__ = str(funding_reader_path)
            # è®¾ç½®__package__å±æ€§
            funding_reader_module.__package__ = "src.utils"
            spec.loader.exec_module(funding_reader_module)
            FundingRateReader = funding_reader_module.FundingRateReader
            print(f"  âœ… FundingRateReader å¯¼å…¥æˆåŠŸï¼ˆimportlibå¯¼å…¥ï¼‰")
        else:
            print(f"  âš ï¸  FundingRateReaderæ–‡ä»¶ä¸å­˜åœ¨: {funding_reader_path}")
    except Exception as e2:
        print(f"  âš ï¸  FundingRateReaderå¯¼å…¥å¤±è´¥: {e2}")
        import traceback
        traceback.print_exc()
# æ”¯æŒç›¸å¯¹å¯¼å…¥å’Œç»å¯¹å¯¼å…¥
try:
    from .preprocessor import preprocess_aggtrades, merge_exchange_data, validate_data
except ImportError:
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç»å¯¹å¯¼å…¥
    import sys
    from pathlib import Path
    project_root = Path(__file__).parent.parent.parent
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    try:
        from src.data.preprocessor import preprocess_aggtrades, merge_exchange_data, validate_data
    except ImportError:
        # å¦‚æœç»å¯¹å¯¼å…¥ä¹Ÿå¤±è´¥ï¼Œä½¿ç”¨importlib
        import importlib.util
        preprocessor_path = project_root / "src" / "data" / "preprocessor.py"
        spec = importlib.util.spec_from_file_location("preprocessor", preprocessor_path)
        preprocessor_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(preprocessor_module)
        preprocess_aggtrades = preprocessor_module.preprocess_aggtrades
        merge_exchange_data = preprocessor_module.merge_exchange_data
        validate_data = preprocessor_module.validate_data


class DataPreparer:
    """æ•°æ®å‡†å¤‡å™¨ï¼Œè´Ÿè´£ä»æ•°æ®æºè¯»å–å¹¶å‡†å¤‡å›æµ‹æ•°æ®"""
    
    def __init__(self, binance_data_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–æ•°æ®å‡†å¤‡å™¨
        
        Args:
            binance_data_dir: Binanceæ•°æ®ç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾„
        """
        self.binance_data_dir = binance_data_dir or BINANCE_AGGTrades_DIR
        if BinanceDataReader is not None:
            self.reader = BinanceDataReader(base_dir=self.binance_data_dir)
        else:
            self.reader = None
        
        # åˆå§‹åŒ–èµ„é‡‘è´¹ç‡è¯»å–å™¨
        if FundingRateReader is not None:
            self.funding_reader = FundingRateReader()
        else:
            self.funding_reader = None
    
    def prepare_binance_aggtrades(
        self,
        symbol: str,
        trading_type: str,
        start_date: datetime,
        end_date: datetime,
        contract_size: float = 1.0
    ) -> np.ndarray:
        """
        å‡†å¤‡Binanceé€ç¬”æˆäº¤æ•°æ®
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·ï¼Œå¦‚ 'BTCUSDT'
            trading_type: äº¤æ˜“ç±»å‹ ('spot', 'um', 'cm')
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            contract_size: åˆçº¦ä¹˜æ•°
        
        Returns:
            å¤„ç†åçš„numpyæ•°ç»„ï¼Œæ ¼å¼: [timestamp, order_side, price, quantity, mm_flag]
        """
        if self.reader is None:
            raise ImportError("BinanceDataReader æœªå¯ç”¨ï¼Œè¯·æ£€æŸ¥ bigdata_plan é¡¹ç›®è·¯å¾„")
        
        # è¯»å–åŸå§‹æ•°æ®
        df = self.reader.read_data(
            trading_type=trading_type,
            data_type='aggTrades',
            symbol=symbol,
            start_date=start_date,
            end_date=end_date
        )
        
        if df.empty:
            return np.empty((0, 5), dtype=np.float64)
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼štimestamp, price, quantity, is_buyer_maker
        data_array = df[['timestamp', 'price', 'quantity', 'is_buyer_maker']].values
        
        # é¢„å¤„ç†æ•°æ®
        processed_data = preprocess_aggtrades(
            data=data_array,
            exchange_flag=0,  # 0è¡¨ç¤ºå¸‚åœºæ•°æ®
            contract_size=contract_size
        )
        
        return processed_data
    
    def prepare_from_duckdb(
        self,
        file_paths: List[str],
        start_ts: Optional[int] = None,
        end_ts: Optional[int] = None,
        contract_size: float = 1.0,
        exchange_flag: int = 0
    ) -> np.ndarray:
        """
        ç›´æ¥ä»DuckDBè¯»å–parquetæ–‡ä»¶å‡†å¤‡æ•°æ®
        
        Args:
            file_paths: parquetæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            start_ts: å¼€å§‹æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
            end_ts: ç»“æŸæ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
            contract_size: åˆçº¦ä¹˜æ•°
            exchange_flag: äº¤æ˜“æ‰€æ ‡è¯†
        
        Returns:
            å¤„ç†åçš„numpyæ•°ç»„
        """
        if not file_paths:
            return np.empty((0, 5), dtype=np.float64)
        
        conn = duckdb.connect()
        
        try:
            # æ„å»ºSQLæŸ¥è¯¢
            file_list_str = str(file_paths)
            
            query = f"""
                SELECT 
                    timestamp as create_time,
                    CASE WHEN is_buyer_maker THEN -1 ELSE 1 END as order_side,
                    price as trade_price,
                    {contract_size} * quantity as trade_quantity,
                    {exchange_flag} as mm
                FROM read_parquet({file_list_str})
            """
            
            if start_ts is not None:
                query += f" WHERE timestamp >= {start_ts}"
            if end_ts is not None:
                if start_ts is not None:
                    query += f" AND timestamp <= {end_ts}"
                else:
                    query += f" WHERE timestamp <= {end_ts}"
            
            query += " ORDER BY timestamp ASC"
            
            # æ‰§è¡ŒæŸ¥è¯¢
            result = conn.execute(query).fetchall()
            
            if not result:
                return np.empty((0, 5), dtype=np.float64)
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            data_array = np.array(result, dtype=np.float64)
            
            return data_array
            
        finally:
            conn.close()
    
    def prepare_multi_exchange(
        self,
        data_sources: List[dict]
    ) -> np.ndarray:
        """
        å‡†å¤‡å¤šä¸ªäº¤æ˜“æ‰€çš„æ•°æ®å¹¶åˆå¹¶
        
        Args:
            data_sources: æ•°æ®æºåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºå­—å…¸ï¼ŒåŒ…å«ï¼š
                - 'type': 'binance' æˆ– 'duckdb'
                - 'exchange_flag': äº¤æ˜“æ‰€æ ‡è¯†
                - å…¶ä»–å‚æ•°æ ¹æ®typeä¸åŒè€Œä¸åŒ
        
        Returns:
            åˆå¹¶åçš„æ•°æ®æ•°ç»„
        """
        data_list = []
        exchange_flags = []
        
        for source in data_sources:
            source_type = source.get('type')
            exchange_flag = source.get('exchange_flag', 0)
            
            if source_type == 'binance':
                data = self.prepare_binance_aggtrades(
                    symbol=source['symbol'],
                    trading_type=source['trading_type'],
                    start_date=source['start_date'],
                    end_date=source['end_date'],
                    contract_size=source.get('contract_size', 1.0)
                )
            elif source_type == 'duckdb':
                data = self.prepare_from_duckdb(
                    file_paths=source['file_paths'],
                    start_ts=source.get('start_ts'),
                    end_ts=source.get('end_ts'),
                    contract_size=source.get('contract_size', 1.0),
                    exchange_flag=exchange_flag
                )
            else:
                continue
            
            if data.size > 0:
                data_list.append(data)
                exchange_flags.append(exchange_flag)
        
        # åˆå¹¶æ•°æ®
        if data_list:
            merged_data = merge_exchange_data(data_list, exchange_flags)
            # éªŒè¯æ•°æ®
            is_valid, error_msg = validate_data(merged_data)
            if not is_valid:
                raise ValueError(f"æ•°æ®éªŒè¯å¤±è´¥: {error_msg}")
            return merged_data
        else:
            return np.empty((0, 5), dtype=np.float64)
    
    def prepare_funding_rate(
        self,
        symbol: str,
        start_date: datetime,
        end_date: datetime
    ) -> np.ndarray:
        """
        å‡†å¤‡èµ„é‡‘è´¹ç‡æ•°æ®
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·ï¼Œå¦‚ 'BTCUSDT'
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
        
        Returns:
            èµ„é‡‘è´¹ç‡numpyæ•°ç»„ï¼Œæ ¼å¼: [[timestamp, funding_rate], ...]
        """
        if self.funding_reader is None:
            # å¦‚æœFundingRateReaderä¸å¯ç”¨ï¼Œè¿”å›ç©ºæ•°ç»„
            print(f"  âš ï¸  FundingRateReader æœªå¯ç”¨ï¼Œè¿”å›ç©ºèµ„é‡‘è´¹ç‡æ•°æ®")
            return np.empty((0, 2), dtype=np.float64)
        
        # è¯»å–èµ„é‡‘è´¹ç‡æ•°æ®
        print(f"  ğŸ“‚ èµ„é‡‘è´¹ç‡æ•°æ®ç›®å½•: {self.funding_reader.BIGDATA_FUNDING_DIR}")
        print(f"  ğŸ“‚ èµ„é‡‘è´¹ç‡æ•°æ®ç›®å½• (tradis): {self.funding_reader.TRADIS_RAW_DIR}")
        
        df = self.funding_reader.read_funding_rate(
            symbol=symbol,
            start_date=start_date,
            end_date=end_date
        )
        
        if df.empty:
            print(f"  âš ï¸  æœªæ‰¾åˆ°èµ„é‡‘è´¹ç‡æ•°æ®")
            return np.empty((0, 2), dtype=np.float64)
        
        # è¾“å‡ºåŠ è½½çš„æ–‡ä»¶ä¿¡æ¯
        # æŸ¥æ‰¾åŠ è½½çš„æ–‡ä»¶
        bigdata_files = self.funding_reader._find_bigdata_files(symbol, start_date, end_date)
        tradis_files = self.funding_reader._find_tradis_files(symbol, start_date, end_date)
        
        print(f"  ğŸ“ æ‰¾åˆ° {len(bigdata_files)} ä¸ª bigdata æ–‡ä»¶:")
        for file_path, file_date in bigdata_files:
            print(f"     - {Path(file_path).name} ({file_date.strftime('%Y-%m')})")
        
        print(f"  ğŸ“ æ‰¾åˆ° {len(tradis_files)} ä¸ª tradis æ–‡ä»¶:")
        for file_path, file_date in tradis_files:
            print(f"     - {Path(file_path).name} ({file_date.strftime('%Y-%m-%d')})")
        
        print(f"  âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡èµ„é‡‘è´¹ç‡è®°å½•")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼štimestamp, funding_rate
        funding_array = df[['funding_time', 'funding_rate']].values.astype(np.float64)
        
        return funding_array
    
    def close(self):
        """å…³é—­æ•°æ®è¯»å–å™¨"""
        if self.reader is not None:
            self.reader.close()

